{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task 6 RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhirajtiwari/upenn/blob/main/task6/Task_6_RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK3PyMYS0qHL",
        "outputId": "e6cf123b-41e0-47d9-e809-3d569bd5c10b"
      },
      "source": [
        "!git clone https://github.com/abhirajtiwari/upenn/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'upenn'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14 (delta 2), reused 9 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zkXHXDi1zj_",
        "outputId": "2497d995-5d44-4946-fae6-82050d911886"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "%pip install --editable ./"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 21116 (delta 5), reused 6 (delta 3), pack-reused 21102\u001b[K\n",
            "Receiving objects: 100% (21116/21116), 9.40 MiB | 27.73 MiB/s, done.\n",
            "Resolving deltas: 100% (15782/15782), done.\n",
            "/content/fairseq\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (1.7.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (2019.12.20)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/7f/4fd83db8570288c3899d8e57666c2841403c15659f3d792a3cb8dc1c6689/sacrebleu-1.5.0-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (1.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (0.8)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (0.29.21)\n",
            "Requirement already satisfied: numpy<1.20.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fairseq==1.0.0a0+4f9831b) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==1.0.0a0+4f9831b) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==1.0.0a0+4f9831b) (3.7.4.3)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/82/22/e684c9e2e59b561dbe36538852e81849122c666c423448e3a5c99362c228/portalocker-2.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+4f9831b) (5.1.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==1.0.0a0+4f9831b) (2.20)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+4f9831b) (3.4.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141231 sha256=b303368284be926014882eab93f50be7496e4a96add833eba8b799a508dc1efa\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, sacrebleu, antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6 portalocker-2.2.1 sacrebleu-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylYe3wFK3VQl",
        "outputId": "8d29a48c-4971-4cde-c96b-bd18a32275a6"
      },
      "source": [
        "import torch\n",
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/fairseq/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fairseq\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/fairseq\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.data_utils_fast' extension\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/data\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.6/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/data\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.6/fairseq/data/data_utils_fast.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.token_block_utils_fast' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/fairseq/libnat.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/data/data_utils_fast.cpython-36m-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.cpython-36m-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/libnat.cpython-36m-x86_64-linux-gnu.so -> fairseq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 655283069/655283069 [00:23<00:00, 27517072.09B/s]\n",
            "1042301B [00:00, 2167487.67B/s]\n",
            "456318B [00:00, 1476067.03B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qTJNIsQp426z",
        "outputId": "cea0fe34-77e2-4e26-b101-3a834edaca35"
      },
      "source": [
        "tokens = roberta.encode('Hello world!')\n",
        "assert tokens.tolist() == [0, 31414, 232, 328, 2]\n",
        "roberta.decode(tokens)  # 'Hello world!'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello world!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OpGTydci5GAQ",
        "outputId": "d032b836-9078-4616-f80c-0136dd9250f0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../upenn/task6/train.tsv\", sep = '\\t')\n",
        "val_df = pd.read_csv(\"../upenn/task6/valid.tsv\", sep='\\t')\n",
        "val_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13361</td>\n",
              "      <td>Loss of taste and smell is best indicator of C...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20228</td>\n",
              "      <td>Me and my girl swear we have already had COVID...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20120</td>\n",
              "      <td>It’s great to have some guidelines around fati...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23604</td>\n",
              "      <td>My partner &amp;amp; I had #coronavirus in late Fe...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31412</td>\n",
              "      <td>Covid week 13 update. Week 11 kidney pain on t...</td>\n",
              "      <td>Self_reports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  ...                label\n",
              "0     13361  ...    Lit-News_mentions\n",
              "1     20228  ...  Nonpersonal_reports\n",
              "2     20120  ...  Nonpersonal_reports\n",
              "3     23604  ...  Nonpersonal_reports\n",
              "4     31412  ...         Self_reports\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Dr5y6-pbdU",
        "outputId": "17b50f9c-5a43-4908-9557-71c15707e20a"
      },
      "source": [
        "print(\"Train\")\n",
        "print(df.dtypes)\n",
        "print(10*'-')\n",
        "print(\"Validation\")\n",
        "print(val_df.dtypes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "tweet_id     int64\n",
            "tweet       object\n",
            "label       object\n",
            "dtype: object\n",
            "----------\n",
            "Validation\n",
            "tweet_id     int64\n",
            "tweet       object\n",
            "label       object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dF4fe1Mpqa4"
      },
      "source": [
        "df.columns = [\"id\", \"tweet\", \"labels\"]\n",
        "val_df.columns = [\"id\", \"tweet\", \"labels\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dh92i423qxCo",
        "outputId": "68d31cd1-9e8f-454d-ead1-6e0277e74ade"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13729</td>\n",
              "      <td>A growing number of Covid-19 patients whose sy...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12399</td>\n",
              "      <td>Medical experts advise that symptoms of the no...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20056</td>\n",
              "      <td>@drdavidsamadi Hubby/I:same symptoms n Novembe...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10175</td>\n",
              "      <td>1/x In the April 11 BC briefing Dr. Bonnie Hen...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12179</td>\n",
              "      <td>Major study PHOSP-COVID investigates health im...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...               labels\n",
              "0  13729  ...    Lit-News_mentions\n",
              "1  12399  ...    Lit-News_mentions\n",
              "2  20056  ...  Nonpersonal_reports\n",
              "3  10175  ...    Lit-News_mentions\n",
              "4  12179  ...    Lit-News_mentions\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "f9bZ9_N6YdKi",
        "outputId": "89d7877e-a6f4-4073-8846-62c1401f5b70"
      },
      "source": [
        "val_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13361</td>\n",
              "      <td>Loss of taste and smell is best indicator of C...</td>\n",
              "      <td>Lit-News_mentions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20228</td>\n",
              "      <td>Me and my girl swear we have already had COVID...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20120</td>\n",
              "      <td>It’s great to have some guidelines around fati...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23604</td>\n",
              "      <td>My partner &amp;amp; I had #coronavirus in late Fe...</td>\n",
              "      <td>Nonpersonal_reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31412</td>\n",
              "      <td>Covid week 13 update. Week 11 kidney pain on t...</td>\n",
              "      <td>Self_reports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...               labels\n",
              "0  13361  ...    Lit-News_mentions\n",
              "1  20228  ...  Nonpersonal_reports\n",
              "2  20120  ...  Nonpersonal_reports\n",
              "3  23604  ...  Nonpersonal_reports\n",
              "4  31412  ...         Self_reports\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts-xijTBq43W",
        "outputId": "5e141952-0d3b-4dd4-a431-712e84d05df8"
      },
      "source": [
        "print(\"Train: \"+str(df.id.nunique())) # 9067\n",
        "print(\"Val: \"+ str(val_df.id.nunique()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 9067\n",
            "Val: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FgvqFlbWhz_",
        "outputId": "d161bfbd-bfbb-4a8c-c734-51eba3adc209"
      },
      "source": [
        "print(\"Train\")\n",
        "print(df.labels.value_counts())\n",
        "print(10*'-')\n",
        "print(\"Validation\")\n",
        "print(val_df.labels.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Lit-News_mentions      4277\n",
            "Nonpersonal_reports    3442\n",
            "Self_reports           1348\n",
            "Name: labels, dtype: int64\n",
            "----------\n",
            "Validation\n",
            "Lit-News_mentions      247\n",
            "Nonpersonal_reports    180\n",
            "Self_reports            73\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkrU2RpNhu0j",
        "outputId": "42cd0327-0a1e-49bd-e40d-2972351e075a"
      },
      "source": [
        "df['labels'].replace({\"Lit-News_mentions\":0, \"Nonpersonal_reports\":1, \"Self_reports\":2}, inplace=True)\n",
        "print(df.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                                              tweet  labels\n",
            "0  13729  A growing number of Covid-19 patients whose sy...       0\n",
            "1  12399  Medical experts advise that symptoms of the no...       0\n",
            "2  20056  @drdavidsamadi Hubby/I:same symptoms n Novembe...       1\n",
            "3  10175  1/x In the April 11 BC briefing Dr. Bonnie Hen...       0\n",
            "4  12179  Major study PHOSP-COVID investigates health im...       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etep3MDqZSAZ",
        "outputId": "4acc4d23-a924-4fc6-f9a4-b90ad93f1361"
      },
      "source": [
        "val_df['labels'].replace({\"Lit-News_mentions\":0, \"Nonpersonal_reports\":1, \"Self_reports\":2}, inplace=True)\n",
        "print(val_df.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                                              tweet  labels\n",
            "0  13361  Loss of taste and smell is best indicator of C...       0\n",
            "1  20228  Me and my girl swear we have already had COVID...       1\n",
            "2  20120  It’s great to have some guidelines around fati...       1\n",
            "3  23604  My partner &amp; I had #coronavirus in late Fe...       1\n",
            "4  31412  Covid week 13 update. Week 11 kidney pain on t...       2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHyvnVQgaDAp"
      },
      "source": [
        "%mkdir ../upenn/task6/Task6_roberta"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2p62HoVy-uT",
        "outputId": "357269db-8d9c-43f3-c56e-2919f4b8fe68"
      },
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train, X_val, Y_train, Y_val = train_test_split(df['tweet'], df['labels'], test_size = 0.2, random_state = 42)\n",
        "X_train = df['tweet']\n",
        "Y_train = df['labels']\n",
        "X_val = val_df['tweet']\n",
        "Y_val = val_df['labels']\n",
        "\n",
        "X_train.reset_index(drop=True, inplace = True)\n",
        "X_val.reset_index(drop=True, inplace = True)\n",
        "Y_train.reset_index(drop=True, inplace = True)\n",
        "Y_val.reset_index(drop=True, inplace=True)\n",
        "for split in ['train', 'val']:\n",
        "  out_fname = 'train' if split == 'train' else 'val'\n",
        "  f1 = open(os.path.join(\"../upenn/task6/Task6_roberta/\", out_fname+'.input0'), 'w')\n",
        "  f2 = open(os.path.join(\"../upenn/task6/Task6_roberta/\", out_fname+'.label'), 'w')\n",
        "  if split=='train':\n",
        "    for i in range(len(X_train)):\n",
        "      f1.write(X_train[i]+'\\n')\n",
        "      f2.write(str(Y_train[i])+'\\n')\n",
        "  else:\n",
        "    for i in range(len(X_val)):\n",
        "      f1.write(X_val[i]+'\\n')\n",
        "      f2.write(str(Y_val[i])+'\\n')\n",
        "      print(i)\n",
        "  f1.close()\n",
        "  f2.close()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmUvqDWjmshG",
        "outputId": "9c4d39c4-c0fc-47d7-91eb-35e99d8c6416"
      },
      "source": [
        "%%shell\n",
        "wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json'\n",
        "wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'\n",
        "\n",
        "for SPLIT in train val; do\n",
        "    python -m examples.roberta.multiprocessing_bpe_encoder \\\n",
        "        --encoder-json encoder.json \\\n",
        "        --vocab-bpe vocab.bpe \\\n",
        "        --inputs \"../upenn/task6/Task6_roberta/$SPLIT.input0\" \\\n",
        "        --outputs \"../upenn/task6/Task6_roberta/$SPLIT.input0.bpe\" \\\n",
        "        --workers 60 \\\n",
        "        --keep-empty\n",
        "done"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-05 03:57:43--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [text/plain]\n",
            "Saving to: ‘encoder.json’\n",
            "\n",
            "encoder.json        100%[===================>]   1018K  2.39MB/s    in 0.4s    \n",
            "\n",
            "2021-02-05 03:57:43 (2.39 MB/s) - ‘encoder.json’ saved [1042301/1042301]\n",
            "\n",
            "--2021-02-05 03:57:43--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [text/plain]\n",
            "Saving to: ‘vocab.bpe’\n",
            "\n",
            "vocab.bpe           100%[===================>] 445.62K  1.51MB/s    in 0.3s    \n",
            "\n",
            "2021-02-05 03:57:44 (1.51 MB/s) - ‘vocab.bpe’ saved [456318/456318]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m7Pt1sf3Ah0",
        "outputId": "6397e5d3-b03e-4cc9-987e-b4be7a882035"
      },
      "source": [
        "%%shell\n",
        "wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt'  \n",
        "\n",
        "fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --trainpref \"../upenn/task6/Task6_roberta/train.input0.bpe\" \\\n",
        "    --validpref \"../upenn/task6/Task6_roberta/val.input0.bpe\" \\\n",
        "    --destdir \"../upenn/task6/Task6_roberta-bin/input0\" \\\n",
        "    --workers 60 \\\n",
        "    --srcdict dict.txt\n",
        "\n",
        "fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --trainpref \"../upenn/task6/Task6_roberta/train.label\" \\\n",
        "    --validpref \"../upenn/task6/Task6_roberta/val.label\" \\\n",
        "    --destdir \"../upenn/task6/Task6_roberta-bin/label\" \\\n",
        "    --workers 60"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-05 03:58:32--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603290 (589K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 589.15K  1.58MB/s    in 0.4s    \n",
            "\n",
            "2021-02-05 03:58:32 (1.58 MB/s) - ‘dict.txt’ saved [603290/603290]\n",
            "\n",
            "2021-02-05 03:58:34 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../upenn/task6/Task6_roberta-bin/input0', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict='dict.txt', suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='../upenn/task6/Task6_roberta/train.input0.bpe', user_dir=None, validpref='../upenn/task6/Task6_roberta/val.input0.bpe', wandb_project=None, workers=60)\n",
            "2021-02-05 03:58:34 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n",
            "2021-02-05 03:58:39 | INFO | fairseq_cli.preprocess | [None] ../upenn/task6/Task6_roberta/train.input0.bpe: 9067 sents, 556650 tokens, 0.0% replaced by <unk>\n",
            "2021-02-05 03:58:39 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n",
            "2021-02-05 03:58:41 | INFO | fairseq_cli.preprocess | [None] ../upenn/task6/Task6_roberta/val.input0.bpe: 500 sents, 30031 tokens, 0.0% replaced by <unk>\n",
            "2021-02-05 03:58:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../upenn/task6/Task6_roberta-bin/input0\n",
            "2021-02-05 03:58:43 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../upenn/task6/Task6_roberta-bin/label', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict=None, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='../upenn/task6/Task6_roberta/train.label', user_dir=None, validpref='../upenn/task6/Task6_roberta/val.label', wandb_project=None, workers=60)\n",
            "2021-02-05 03:58:43 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n",
            "2021-02-05 03:58:44 | INFO | fairseq_cli.preprocess | [None] ../upenn/task6/Task6_roberta/train.label: 9067 sents, 18134 tokens, 0.0% replaced by <unk>\n",
            "2021-02-05 03:58:44 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n",
            "2021-02-05 03:58:44 | INFO | fairseq_cli.preprocess | [None] ../upenn/task6/Task6_roberta/val.label: 500 sents, 1000 tokens, 0.0% replaced by <unk>\n",
            "2021-02-05 03:58:44 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../upenn/task6/Task6_roberta-bin/label\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDHumSWjWEBU",
        "outputId": "826586c7-df45-4e14-fc1f-a135048de1f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNJeHBirn3QJ",
        "outputId": "a58cfd33-d835-4736-c5af-91e013f1343d"
      },
      "source": [
        "%%shell\n",
        "TOTAL_NUM_UPDATES=3614  # 10 epochs through UPENN for bsz 32\n",
        "WARMUP_UPDATES=217      # 6 percent of the number of updates\n",
        "LR=1e-05                # Peak LR for polynomial LR scheduler.\n",
        "HEAD_NAME=task6_head    # Custom name for the classification head.\n",
        "NUM_CLASSES=3           # Number of classes for the classification task.\n",
        "MAX_SENTENCES=8         # Batch size.\n",
        "ROBERTA_PATH=/content/fairseq/checkpoints/check1.pt\n",
        "\n",
        "CUDA_VISIBLE_DEVICES=0 fairseq-train ../upenn/task6/Task6_roberta-bin/ \\\n",
        "    --restore-file $ROBERTA_PATH \\\n",
        "    --max-positions 512 \\\n",
        "    --batch-size $MAX_SENTENCES \\\n",
        "    --max-tokens 4400 \\\n",
        "    --task sentence_prediction \\\n",
        "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "    --required-batch-size-multiple 1 \\\n",
        "    --init-token 0 --separator-token 2 \\\n",
        "    --arch roberta_large \\\n",
        "    --criterion sentence_prediction \\\n",
        "    --classification-head-name $HEAD_NAME \\\n",
        "    --num-classes $NUM_CLASSES \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 \\\n",
        "    --weight-decay 0.1 --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-06 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --lr-scheduler polynomial_decay --lr $LR --total-num-update $TOTAL_NUM_UPDATES --warmup-updates $WARMUP_UPDATES \\\n",
        "    --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
        "    --max-epoch 3 \\\n",
        "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "    --shorten-method \"truncate\" \\\n",
        "    --find-unused-parameters \\\n",
        "    --update-freq 4"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-05 04:41:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': 8, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': 8, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 3, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/content/fairseq/checkpoints/check1.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_large', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='task6_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../upenn/task6/Task6_roberta-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=128, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=3, max_positions=512, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=3, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/content/fairseq/checkpoints/check1.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, separator_token=2, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=1.0, tokenizer=None, total_num_update='3614', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=217, weight_decay=0.1, zero_sharding='none'), 'task': Namespace(_name='sentence_prediction', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='task6_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../upenn/task6/Task6_roberta-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=128, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=3, max_positions=512, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=3, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/content/fairseq/checkpoints/check1.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, separator_token=2, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=1.0, tokenizer=None, total_num_update='3614', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=217, weight_decay=0.1, zero_sharding='none'), 'criterion': Namespace(_name='sentence_prediction', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='task6_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../upenn/task6/Task6_roberta-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=128, gen_subset='test', heartbeat_timeout=-1, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=3, max_positions=512, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=3, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/content/fairseq/checkpoints/check1.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, separator_token=2, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=1.0, tokenizer=None, total_num_update='3614', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=217, weight_decay=0.1, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 217, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 3614.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
            "2021-02-05 04:41:07 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
            "2021-02-05 04:41:07 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n",
            "2021-02-05 04:41:07 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../upenn/task6/Task6_roberta-bin/input0/valid\n",
            "2021-02-05 04:41:07 | INFO | fairseq.data.data_utils | loaded 500 examples from: ../upenn/task6/Task6_roberta-bin/label/valid\n",
            "2021-02-05 04:41:07 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 500\n",
            "2021-02-05 04:41:18 | INFO | fairseq_cli.train | RobertaModel(\n",
            "  (encoder): RobertaEncoder(\n",
            "    (sentence_encoder): TransformerSentenceEncoder(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
            "      (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
            "      (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (12): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (13): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (14): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (15): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (16): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (17): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (18): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (19): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (20): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (21): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (22): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (23): TransformerSentenceEncoderLayer(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (activation_dropout_module): FairseqDropout()\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (lm_head): RobertaLMHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (classification_heads): ModuleDict(\n",
            "    (task6_head): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-02-05 04:41:18 | INFO | fairseq_cli.train | task: SentencePredictionTask\n",
            "2021-02-05 04:41:18 | INFO | fairseq_cli.train | model: RobertaModel\n",
            "2021-02-05 04:41:18 | INFO | fairseq_cli.train | criterion: SentencePredictionCriterion\n",
            "2021-02-05 04:41:18 | INFO | fairseq_cli.train | num. model params: 356,463,708 (num. trained: 356,463,708)\n",
            "2021-02-05 04:41:26 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
            "2021-02-05 04:41:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-02-05 04:41:26 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.726 GB ; name = Tesla T4                                \n",
            "2021-02-05 04:41:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-02-05 04:41:26 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-02-05 04:41:26 | INFO | fairseq_cli.train | max tokens per GPU = 4400 and batch size per GPU = 8\n",
            "2021-02-05 04:41:26 | INFO | fairseq.trainer | Preparing to load checkpoint /content/fairseq/checkpoints/check1.pt\n",
            "tcmalloc: large alloc 1425858560 bytes == 0x1211b0000 @  0x7f421c2efb6b 0x7f421c30f379 0x7f41bf3ce74e 0x7f41bf3d07b6 0x7f41fa56999d 0x7f4209c2c8d0 0x7f42098aac1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x5a4c61 0x5a4fb8 0x4e012e 0x50a461 0x50beb4 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900\n",
            "tcmalloc: large alloc 1425858560 bytes == 0x17617e000 @  0x7f421c2efb6b 0x7f421c30f379 0x7f41bf3ce74e 0x7f41bf3d07b6 0x7f41fa56999d 0x7f4209c2c8d0 0x7f42098aac1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x508ec2 0x5a4c61 0x5a4fb8 0x4e012e 0x50a461 0x50beb4 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900\n",
            "2021-02-05 04:43:31 | INFO | fairseq.trainer | Loaded checkpoint /content/fairseq/checkpoints/check1.pt (epoch 5 @ 0 updates)\n",
            "2021-02-05 04:43:31 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-02-05 04:43:31 | INFO | fairseq.data.data_utils | loaded 9,067 examples from: ../upenn/task6/Task6_roberta-bin/input0/train\n",
            "2021-02-05 04:43:31 | INFO | fairseq.data.data_utils | loaded 9,067 examples from: ../upenn/task6/Task6_roberta-bin/label/train\n",
            "2021-02-05 04:43:31 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 9067\n",
            "epoch 001:   0% 0/284 [00:00<?, ?it/s]2021-02-05 04:43:31 | INFO | fairseq.trainer | begin training epoch 1\n",
            "epoch 001: 100% 283/284 [03:03<00:00,  1.55it/s, loss=0.135, nll_loss=0.002, accuracy=97, wps=3129.9, ups=1.56, wpb=2008.8, bsz=32, num_updates=200, lr=9.21659e-06, gnorm=5.935, loss_scale=8, train_wall=64, gb_free=6.7, wall=254]2021-02-05 04:46:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   2% 1/63 [00:00<00:10,  5.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 4/63 [00:00<00:07,  7.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 7/63 [00:00<00:05,  9.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  16% 10/63 [00:00<00:04, 11.48it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 13/63 [00:00<00:03, 13.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 16/63 [00:00<00:03, 15.08it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 19/63 [00:00<00:02, 16.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 22/63 [00:01<00:02, 18.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  40% 25/63 [00:01<00:01, 19.01it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 28/63 [00:01<00:01, 19.31it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 31/63 [00:01<00:01, 20.70it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 34/63 [00:01<00:01, 21.50it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 37/63 [00:01<00:01, 22.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 40/63 [00:01<00:01, 22.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 43/63 [00:02<00:00, 23.10it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 46/63 [00:02<00:00, 21.96it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  78% 49/63 [00:02<00:00, 22.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 52/63 [00:02<00:00, 22.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 55/63 [00:02<00:00, 22.13it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 58/63 [00:02<00:00, 23.36it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 61/63 [00:02<00:00, 22.81it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-02-05 04:46:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.169 | nll_loss 0.003 | accuracy 96.2 | wps 11155.7 | wpb 484.6 | bsz 7.9 | num_updates 284\n",
            "2021-02-05 04:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 284 updates\n",
            "tcmalloc: large alloc 1425858560 bytes == 0x1215b0000 @  0x7f421c2efb6b 0x7f421c30f379 0x7f41bf3ce74e 0x7f41bf3d07b6 0x7f41f9e3ad53 0x7f41f98258cf 0x7f41f9b3ccac 0x7f41f9ae831b 0x7f41f9b07135 0x7f41f9ae2b4b 0x7f41f9ae831b 0x7f41f9b07135 0x7f41f9bd12be 0x7f41fb0e3d6e 0x7f41f9ae831b 0x7f41f9b07135 0x7f41f9ae2b4b 0x7f41f9ae831b 0x7f41f9b07135 0x7f41f9bd12be 0x7f41f9813910 0x7f41f9d8c3f3 0x7f41f9390a68 0x7f41f9b0e643 0x7f41f9e0cff9 0x7f4209778902 0x7f42098916ec 0x50a4a5 0x50beb4 0x507be4 0x509900\n",
            "2021-02-05 04:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint1.pt\n",
            "2021-02-05 04:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 284 updates, score 96.2) (writing took 334.01818253400006 seconds)\n",
            "2021-02-05 04:52:12 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-02-05 04:52:12 | INFO | train | epoch 001 | loss 0.161 | nll_loss 0.003 | accuracy 96.5 | wps 1085 | ups 0.54 | wpb 1992 | bsz 31.9 | num_updates 284 | lr 9.80277e-06 | gnorm 6.523 | loss_scale 16 | train_wall 182 | gb_free 6.7 | wall 645\n",
            "epoch 002:   0% 0/284 [00:00<?, ?it/s]2021-02-05 04:52:12 | INFO | fairseq.trainer | begin training epoch 2\n",
            "epoch 002: 100% 283/284 [03:04<00:00,  1.59it/s, loss=0.148, nll_loss=0.002, accuracy=96.9, wps=3098.2, ups=1.54, wpb=2006, bsz=32, num_updates=500, lr=9.16691e-06, gnorm=5.791, loss_scale=32, train_wall=64, gb_free=6.7, wall=786]2021-02-05 04:55:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   2% 1/63 [00:00<00:10,  5.95it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   6% 4/63 [00:00<00:07,  7.63it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  11% 7/63 [00:00<00:05,  9.67it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  16% 10/63 [00:00<00:04, 11.54it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  21% 13/63 [00:00<00:03, 13.45it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  25% 16/63 [00:00<00:03, 15.07it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  30% 19/63 [00:00<00:02, 17.03it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  35% 22/63 [00:01<00:02, 18.22it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  40% 25/63 [00:01<00:01, 19.20it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  44% 28/63 [00:01<00:01, 19.32it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  49% 31/63 [00:01<00:01, 20.77it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  54% 34/63 [00:01<00:01, 21.69it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  59% 37/63 [00:01<00:01, 22.32it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  63% 40/63 [00:01<00:01, 22.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  68% 43/63 [00:02<00:00, 23.24it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  73% 46/63 [00:02<00:00, 21.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  78% 49/63 [00:02<00:00, 22.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  83% 52/63 [00:02<00:00, 23.00it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  87% 55/63 [00:02<00:00, 22.27it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  92% 58/63 [00:02<00:00, 23.54it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  97% 61/63 [00:02<00:00, 22.92it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-02-05 04:55:19 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.128 | nll_loss 0.002 | accuracy 96.8 | wps 11148.2 | wpb 484.6 | bsz 7.9 | num_updates 568 | best_accuracy 96.8\n",
            "2021-02-05 04:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 568 updates\n",
            "2021-02-05 04:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint2.pt\n",
            "2021-02-05 05:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 568 updates, score 96.8) (writing took 338.1186997769996 seconds)\n",
            "2021-02-05 05:00:57 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-02-05 05:00:57 | INFO | train | epoch 002 | loss 0.146 | nll_loss 0.002 | accuracy 96.9 | wps 1076.1 | ups 0.54 | wpb 1992 | bsz 31.9 | num_updates 568 | lr 8.96674e-06 | gnorm 6.107 | loss_scale 64 | train_wall 183 | gb_free 6.7 | wall 1171\n",
            "epoch 003:   0% 0/284 [00:00<?, ?it/s]2021-02-05 05:00:57 | INFO | fairseq.trainer | begin training epoch 3\n",
            "epoch 003: 100% 283/284 [03:04<00:00,  1.57it/s, loss=0.168, nll_loss=0.003, accuracy=96.5, wps=3015.1, ups=1.52, wpb=1986.1, bsz=32, num_updates=800, lr=8.28378e-06, gnorm=6.47, loss_scale=256, train_wall=65, gb_free=6.7, wall=1324]2021-02-05 05:04:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   2% 1/63 [00:00<00:09,  6.24it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   6% 4/63 [00:00<00:07,  7.97it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  11% 7/63 [00:00<00:05, 10.06it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  16% 10/63 [00:00<00:04, 11.99it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  21% 13/63 [00:00<00:03, 13.87it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  25% 16/63 [00:00<00:03, 15.54it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  30% 19/63 [00:00<00:02, 17.38it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  35% 22/63 [00:01<00:02, 18.35it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  40% 25/63 [00:01<00:01, 19.26it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  44% 28/63 [00:01<00:01, 19.52it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  49% 31/63 [00:01<00:01, 21.03it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  54% 34/63 [00:01<00:01, 21.86it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  59% 37/63 [00:01<00:01, 22.54it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  63% 40/63 [00:01<00:01, 22.90it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  68% 43/63 [00:01<00:00, 23.15it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  73% 46/63 [00:02<00:00, 21.89it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  78% 49/63 [00:02<00:00, 22.79it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  83% 52/63 [00:02<00:00, 23.13it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  87% 55/63 [00:02<00:00, 22.14it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  92% 58/63 [00:02<00:00, 23.27it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  97% 61/63 [00:02<00:00, 22.68it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-02-05 05:04:06 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.127 | nll_loss 0.002 | accuracy 96.8 | wps 11157.5 | wpb 484.6 | bsz 7.9 | num_updates 852 | best_accuracy 96.8\n",
            "2021-02-05 05:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 852 updates\n",
            "2021-02-05 05:05:32 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint3.pt\n",
            "2021-02-05 05:09:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 852 updates, score 96.8) (writing took 338.5643603870003 seconds)\n",
            "2021-02-05 05:09:44 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-02-05 05:09:44 | INFO | train | epoch 003 | loss 0.138 | nll_loss 0.002 | accuracy 97.1 | wps 1073.8 | ups 0.54 | wpb 1992 | bsz 31.9 | num_updates 852 | lr 8.1307e-06 | gnorm 5.736 | loss_scale 256 | train_wall 184 | gb_free 6.7 | wall 1698\n",
            "2021-02-05 05:09:44 | INFO | fairseq_cli.train | done training in 1573.4 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9zIeNufevyj"
      },
      "source": [
        "#%rm checkpoints/checkpoint1.pt checkpoints/checkpoint2.pt checkpoints/checkpoint3.pt checkpoints/checkpoint_last.pt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gml36iwmSprs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5a9f0b-0539-42a8-fd11-14b0ae6da8b1"
      },
      "source": [
        "from fairseq.models.roberta import RobertaModel\n",
        "roberta = RobertaModel.from_pretrained(\n",
        "    'checkpoints',\n",
        "    checkpoint_file='check7.pt',\n",
        "    data_name_or_path='/content/upenn/task6/Task6_roberta-bin'\n",
        ")\n",
        "roberta.eval()  # disable dropout"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaHubInterface(\n",
              "  (model): RobertaModel(\n",
              "    (encoder): RobertaEncoder(\n",
              "      (sentence_encoder): TransformerSentenceEncoder(\n",
              "        (dropout_module): FairseqDropout()\n",
              "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
              "        (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (6): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (7): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (8): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (9): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (10): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (11): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (12): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (13): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (14): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (15): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (16): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (17): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (18): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (19): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (20): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (21): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (22): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (23): TransformerSentenceEncoderLayer(\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (classification_heads): ModuleDict(\n",
              "      (task6_head): RobertaClassificationHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVEuXDAWoLnu",
        "outputId": "5564792b-0b2b-4480-d1bf-65d49698cf6e"
      },
      "source": [
        "X_val"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Loss of taste and smell is best indicator of C...\n",
              "1      Me and my girl swear we have already had COVID...\n",
              "2      It’s great to have some guidelines around fati...\n",
              "3      My partner &amp; I had #coronavirus in late Fe...\n",
              "4      Covid week 13 update. Week 11 kidney pain on t...\n",
              "                             ...                        \n",
              "495    I’m getting tested for COVID-19 rn My mom thin...\n",
              "496    Tuesday am: feeling like havent slept at all. ...\n",
              "497    @DanTopp64 @kingmanmarie39 I don't think that'...\n",
              "498    My dad died of a heart problem caused by rheum...\n",
              "499    Many Covid-19 patients are reporting neurologi...\n",
              "Name: tweet, Length: 500, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAo5WZgxV9iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139c81e1-a2b9-486e-aca6-e2904ea0d89c"
      },
      "source": [
        "from tqdm import tqdm\n",
        "label_fn = lambda label: roberta.task.label_dictionary.string(\n",
        "    [label + roberta.task.label_dictionary.nspecial]\n",
        ")\n",
        "preds, labels = [], []\n",
        "for i in tqdm(range(len(X_val))):\n",
        "  tokens = roberta.encode(X_val[i])\n",
        "  pred = label_fn(roberta.predict('task6_head',tokens).argmax().item())\n",
        "  preds.append(pred)\n",
        "  labels.append(Y_val[i])\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [06:59<00:00,  1.19it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keTzhnpWriQa",
        "outputId": "99845107-9d17-41d3-be40-5813498bcd1f"
      },
      "source": [
        "print(list(map(str,labels)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '1', '1', '2', '0', '0', '0', '0', '1', '1', '1', '0', '2', '0', '0', '1', '1', '0', '1', '2', '0', '0', '0', '0', '1', '0', '2', '2', '1', '1', '1', '0', '1', '0', '0', '1', '0', '2', '0', '0', '2', '0', '1', '2', '2', '0', '0', '2', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '2', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '2', '1', '0', '0', '0', '1', '2', '0', '1', '0', '0', '0', '2', '2', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '2', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '1', '1', '2', '0', '0', '0', '0', '2', '2', '2', '0', '1', '1', '0', '0', '0', '2', '0', '1', '2', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '2', '0', '2', '1', '2', '0', '0', '0', '2', '2', '1', '1', '0', '0', '0', '0', '2', '1', '0', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '2', '1', '0', '0', '0', '1', '2', '0', '0', '0', '0', '1', '0', '1', '0', '2', '0', '0', '2', '1', '1', '0', '0', '1', '1', '0', '0', '1', '2', '0', '1', '1', '0', '0', '1', '2', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '2', '1', '0', '1', '1', '1', '0', '1', '2', '2', '0', '0', '0', '1', '2', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '2', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '2', '0', '2', '0', '2', '1', '0', '2', '0', '1', '1', '0', '0', '1', '0', '0', '2', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '2', '0', '0', '1', '1', '0', '0', '0', '2', '0', '0', '1', '0', '0', '1', '2', '1', '1', '0', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '0', '0', '2', '1', '2', '0', '0', '0', '1', '2', '1', '0', '0', '1', '2', '0', '1', '1', '0', '2', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '2', '0', '0', '0', '0', '1', '0', '1', '2', '1', '0', '0', '0', '2', '1', '1', '0', '0', '0', '0', '1', '2', '0', '1', '0', '1', '1', '1', '0', '1', '0', '0', '2', '1', '2', '0', '0', '0', '1', '0', '0', '2', '0', '1', '2', '1', '2', '1', '0', '0', '0', '0', '2', '1', '0', '1', '1', '2', '2', '1', '2', '0', '1', '0', '0', '0', '1', '0', '0', '2', '0', '1', '0', '1', '1', '2', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '2', '0', '0', '1', '0', '0', '0', '2', '1', '0', '1', '1', '2', '1', '0', '1', '1', '1', '1', '1', '2', '1', '1', '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAKKY9xoXuxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28493692-41eb-4c8c-e1a9-a168c6c477da"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(list(map(str,labels)), preds)\n",
        "print(report)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98       247\n",
            "           1       0.95      0.97      0.96       180\n",
            "           2       0.97      0.96      0.97        73\n",
            "\n",
            "    accuracy                           0.97       500\n",
            "   macro avg       0.97      0.97      0.97       500\n",
            "weighted avg       0.97      0.97      0.97       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "3h_H7jfFt8iA",
        "outputId": "3ac0f295-8c5d-414e-df45-a414b47f49a6"
      },
      "source": [
        "#@title Input sample tweet\n",
        "input_tweet = 'New Covid strains could be extremely profitable for Pfizer, Moderna, and other drugmakers https://trib.al/UZ17lyb via  @BW' #@param {type:\"string\"}\n",
        "tokens = roberta.encode(input_tweet)\n",
        "pred = label_fn(roberta.predict('task6_head',tokens).argmax().item())\n",
        "\n",
        "rev_dict = {0:\"Lit-News_mentions\", 1:\"Nonpersonal_reports\", 2:\"Self_reports\"}\n",
        "print(rev_dict[int(pred)])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lit-News_mentions\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}